# 意图识别面试通关指南：从基础问答到场景落地

## 引言

意图识别（Intent Recognition）作为任务型对话系统（Task-oriented Dialogue System）的核心组件，一直是 NLP 算法岗面试的高频考点。本文整理了从基础概念到工程实践的常见面试题，助你从容应对。

## 第一部分：基础概念与算法

### Q1: 什么是意图识别？它在对话系统中的位置是什么？
**参考回答：**
意图识别本质上是一个**文本分类**任务。它的目标是将用户的自然语言输入映射到预定义的意图类别（如“查天气”、“订机票”、“播放音乐”）中。
在对话系统架构中，它通常位于 NLU（自然语言理解）模块，紧随分词/预处理之后，与槽位填充（Slot Filling）共同构成 NLU 的两大核心任务。

### Q2: 常见的意图识别算法有哪些？各有什么优缺点？
**参考回答：**
1.  **基于规则/模板匹配**：
    *   **优点**：冷启动快，准确率高（针对特定case），可解释性强。
    *   **缺点**：泛化能力差，维护成本随规则数量指数级上升。
2.  **传统机器学习（SVM/LR/Naive Bayes）**：
    *   **优点**：训练速度快，对小样本数据相对友好，模型轻量。
    *   **缺点**：需要繁琐的特征工程（TF-IDF, N-gram），难以捕捉深层语义。
3.  **深度学习（CNN/RNN/LSTM）**：
    *   **优点**：自动提取特征，捕捉序列信息（RNN）或局部特征（CNN）。
    *   **缺点**：需要较多标注数据，训练时间较长。
4.  **预训练模型（BERT/RoBERTa）**：
    *   **优点**：SOTA 效果，强大的语义表征能力，少样本下微调效果依然出色。
    *   **缺点**：模型庞大，推理延迟高（需蒸馏或量化）。

### Q3: 意图识别和槽位填充通常是如何联合建模的？
**参考回答：**
虽然可以分别训练两个模型，但联合建模（Joint Learning）通常效果更好，因为两者共享语义信息。
*   **常见架构**：BERT + CRF 或 BiLSTM + CRF。
*   **机制**：编码层共享（如 BERT 输出），意图识别通常取 `[CLS]` token 进行分类，槽位填充则对每个 token 进行序列标注。
*   **Loss**：$Loss = Loss_{intent} + \alpha \cdot Loss_{slot}$。

## 第二部分：进阶挑战与优化

### Q4: 如何处理“多意图”问题（Multi-label Intent Detection）？
**参考回答：**
用户一句话可能包含多个意图（例如：“帮我关灯并定个明早八点的闹钟”）。
*   **方法一**：将多意图组合视为新的单标签（Label Powerset），但会导致标签空间爆炸。
*   **方法二**：将 Softmax 替换为 Sigmoid，对每个类别独立预测概率（阈值截断）。
*   **方法三**：序列生成式（Seq2Seq），直接生成意图序列。

### Q5: 遇到“意图不明”或“OOD（Out-of-Domain）”意图怎么办？
**参考回答：**
这是工业界非常关注的问题。
1.  **阈值法**：如果最高置信度低于设定阈值（如 0.7），则判为 OOD，触发兜底回复或澄清反问。
2.  **引入“其它”类**：在训练集中专门构造一个 `Other` 类，包含各种非业务域的语料。
3.  **异常检测算法**：利用度量学习（Metric Learning）或 OpenMax 等方法，判断输入样本与已知类别的距离。

### Q6: 数据不平衡（Long-tail）如何解决？
**参考回答：**
*   **数据增强**：回译（Back Translation）、EDA（同义词替换、随机插入/删除）、Mixup。
*   **重采样**：对少样本类别过采样，或对多样本类别欠采样。
*   **Loss 调整**：使用 Focal Loss 或加权 CrossEntropy，增加难分样本或少样本类别的权重。
*   **Few-shot Learning**：利用原型网络（Prototypical Networks）等元学习方法。

## 第三部分：工程落地与评估

### Q7: 意图识别的评估指标有哪些？
**参考回答：**
*   **Accuracy**：整体准确率。
*   **Precision / Recall / F1-score**：针对每个类别的指标，尤其是 F1-score（Macro-F1 或 Micro-F1）更能反映模型在不平衡数据下的表现。
*   **Confusion Matrix**：混淆矩阵，用于分析哪些意图容易混淆。

### Q8: 上线后发现某个意图召回率低，如何排查？
**参考回答：**
1.  **Badcase 分析**：查看漏召回的样本有什么特征（如包含未见过的实体、特殊的句式结构）。
2.  **数据检查**：训练集中该意图的样本是否过少？标注质量是否参差不齐？
3.  **混淆分析**：是否被误判为了某个特定的相似意图？如果是，可能需要合并意图或增加区分性特征。

## 结语

面试中除了背诵八股文，更重要的是结合自己的项目经历，阐述在面对具体困难（如数据少、噪音大、实时性要求高）时的思考过程和解决方案。祝大家面试顺利！
